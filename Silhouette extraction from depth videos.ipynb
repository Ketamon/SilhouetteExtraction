{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeImage(img):\n",
    "    maxValue=np.amax(img)\n",
    "    return img/maxValue,int(maxValue)\n",
    "\n",
    "def removeFloor(img_array,threshold1):\n",
    "    height = img_array.shape[0]\n",
    "    width = img_array.shape[1]\n",
    "    cy=int(height/2)  #center y\n",
    "    fy=580  #focal length y\n",
    "    z=5000  #initial min depth\n",
    "\n",
    "    croppedRow = img_array[-1][np.nonzero(img_array[-1])]\n",
    "    #z=stats.mode(img_array[-1]).mode[0]\n",
    "    if (len(croppedRow)>0):\n",
    "        z=stats.mode(croppedRow).mode[0]     #initial floor depth\n",
    "    else:\n",
    "        z=75\n",
    "\n",
    "    Y=z*(height-cy)/fy                       #actual y of floor\n",
    "    Y=Y-threshold1\n",
    "    \n",
    "    for i in range(height-1,cy-1,-1):\n",
    "        z1=(Y*fy)/((i+1)-cy)                   #depth of Y height\n",
    "\n",
    "        for j in range(width):\n",
    "            if (img_array[i][j]>z1):\n",
    "                img_array[i][j]=0\n",
    "\n",
    "    output,__=normalizeImage(img_array)\n",
    "    return output\n",
    "\n",
    "def removeFar(img,threshold):\n",
    "    maxVal = np.amax(img)\n",
    "    ret,output = cv2.threshold(img,threshold,maxVal,cv2.THRESH_TOZERO_INV)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UFarray:\n",
    "    def __init__(self):\n",
    "        # Array which holds label -> set equivalences\n",
    "        self.P = []\n",
    "\n",
    "        # Name of the next label, when one is created\n",
    "        self.label = 0\n",
    "\n",
    "    def makeLabel(self):\n",
    "        r = self.label\n",
    "        self.label += 1\n",
    "        self.P.append(r)\n",
    "        return r\n",
    "    \n",
    "    # Makes all nodes \"in the path of node i\" point to root\n",
    "    def setRoot(self, i, root):\n",
    "        while self.P[i] < i:\n",
    "            j = self.P[i]\n",
    "            self.P[i] = root\n",
    "            i = j\n",
    "        self.P[i] = root\n",
    "\n",
    "    # Finds the root node of the tree containing node i\n",
    "    def findRoot(self, i):\n",
    "        while self.P[i] < i:\n",
    "            i = self.P[i]\n",
    "        return i\n",
    "    \n",
    "    # Finds the root of the tree containing node i\n",
    "    # Simultaneously compresses the tree\n",
    "    def find(self, i):\n",
    "        root = self.findRoot(i)\n",
    "        self.setRoot(i, root)\n",
    "        return root\n",
    "    \n",
    "    # Joins the two trees containing nodes i and j\n",
    "    # Modified to be less agressive about compressing paths\n",
    "    # because performance was suffering some from over-compression\n",
    "    def union(self, i, j):\n",
    "        if i != j:\n",
    "            root = self.findRoot(i)\n",
    "            rootj = self.findRoot(j)\n",
    "            if root > rootj: root = rootj\n",
    "            self.setRoot(j, root)\n",
    "            self.setRoot(i, root)\n",
    "    \n",
    "    def flatten(self):\n",
    "        for i in range(1, len(self.P)):\n",
    "            self.P[i] = self.P[self.P[i]]\n",
    "\n",
    "\n",
    "def get_components(frame, threshold):\n",
    "    width, height = frame.shape[1], frame.shape[0]\n",
    " \n",
    "    # Union find data structure\n",
    "    uf = UFarray()\n",
    " \n",
    "    # Dictionary of point:label pairs\n",
    "    labels = {}\n",
    " \n",
    "    for y, x in product(range(height), range(width)):\n",
    "\n",
    " \n",
    "        #\n",
    "        # Pixel names were chosen as shown:\n",
    "        #\n",
    "        #   -------------\n",
    "        #   | a | b | c |\n",
    "        #   -------------\n",
    "        #   | d | e |   |\n",
    "        #   -------------\n",
    "        #   |   |   |   |\n",
    "        #   -------------\n",
    "        #\n",
    "        # The current pixel is e\n",
    "        # a, b, c, and d are its neighbors of interest\n",
    "        #\n",
    "        # 255 is white, 0 is black\n",
    "        # White pixels part of the background, so they are ignored\n",
    "        # If a pixel lies outside the bounds of the image, it default to white\n",
    "        #\n",
    " \n",
    "        # If the current pixel is white, it's obviously not a component...\n",
    "        if frame[y, x] == 0:\n",
    "            pass\n",
    " \n",
    "        # If pixel b is in the image and black:\n",
    "        #   a, d, and c are its neighbors, so they are all part of the same component\n",
    "        #   Therefore, there is no reason to check their labels\n",
    "        #   so simply assign b's label to e\n",
    "        elif y > 0 and abs(frame[y-1,x]-frame[y,x]) < threshold:\n",
    "            labels[y,x] = labels[(y-1,x)]\n",
    " \n",
    "        # If pixel c is in the image and black:\n",
    "        #   b is its neighbor, but a and d are not\n",
    "        #   Therefore, we must check a and d's labels\n",
    "        elif x+1 < width and y > 0 and abs(frame[y-1,x+1]-frame[y,x]) < threshold:\n",
    "            c = labels[(y-1),x+1]\n",
    "            labels[y,x] = c\n",
    " \n",
    "            # If pixel a is in the image and black:\n",
    "            #   Then a and c are connected through e\n",
    "            #   Therefore, we must union their sets\n",
    "            if x > 0 and abs(frame[y-1,x-1]-frame[y, x]) < threshold:\n",
    "                a = labels[(y-1,x-1)]\n",
    "                uf.union(c, a)\n",
    " \n",
    "            # If pixel d is in the image and black:\n",
    "            #   Then d and c are connected through e\n",
    "            #   Therefore we must union their sets\n",
    "            elif x > 0 and abs(frame[y, x-1]-frame[y, x]) < threshold:\n",
    "                d = labels[(y, x-1)]\n",
    "                uf.union(c, d)\n",
    " \n",
    "        # If pixel a is in the image and black:\n",
    "        #   We already know b and c are white\n",
    "        #   d is a's neighbor, so they already have the same label\n",
    "        #   So simply assign a's label to e\n",
    "        elif x > 0 and y > 0 and abs(frame[y-1,x-1]-frame[y,x]) < threshold:\n",
    "            labels[y,x] = labels[(y-1,x-1)]\n",
    " \n",
    "        # If pixel d is in the image and black\n",
    "        #   We already know a, b, and c are white\n",
    "        #   so simpy assign d's label to e\n",
    "        elif x > 0 and abs(frame[y, x-1]-frame[y, x]) < threshold:\n",
    "            labels[y, x] = labels[(y, x-1)]\n",
    " \n",
    "        # All the neighboring pixels are white,\n",
    "        # Therefore the current pixel is a new component\n",
    "        else: \n",
    "            labels[y, x] = uf.makeLabel()\n",
    "  \n",
    "    uf.flatten()\n",
    "\n",
    "    for (y, x) in labels:\n",
    "        # Name of the component the current point belongs to\n",
    "        component = uf.find(labels[(y, x)])\n",
    "        # Update the labels with correct information\n",
    "        labels[(y, x)] = component\n",
    " \n",
    "    return labels\n",
    "\n",
    "def getStatsOfLabel(frame,label,labels):\n",
    "    img = np.zeros(frame.shape)\n",
    "    for y, x in product(range(img.shape[0]), range(img.shape[1])):\n",
    "        if (y,x) in labels and labels[(y,x)] == label:\n",
    "            img[y,x]=255\n",
    "        else:\n",
    "            img[y,x]=0\n",
    "    \n",
    "    img = img.astype(np.uint8)\n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_TC89_L1)\n",
    "    x,y,w,h = cv2.boundingRect(contours[0])\n",
    "    return [x+w/2,y+h/2],w,h\n",
    "\n",
    "def getCentroid(img):\n",
    "    img,__=normalizeImage(img)\n",
    "    img = (img*255).astype(np.uint8)\n",
    "    cnts,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_TC89_L1)\n",
    "    boxes = []\n",
    "    for c in cnts:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        boxes.append([x,y, x+w,y+h])\n",
    "\n",
    "    boxes = np.asarray(boxes)\n",
    "    # need an extra \"min/max\" for contours outside the frame\n",
    "    left = np.min(boxes[:,0])\n",
    "    top = np.min(boxes[:,1])\n",
    "    right = np.max(boxes[:,2])\n",
    "    bottom = np.max(boxes[:,3])\n",
    "\n",
    "    return [(left+right)/2,(top+bottom)/2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthFrames = np.fromfile(<envFilePath>, dtype = \"uint16\")\n",
    "numOfFrames = int(depthFrames.shape[0]/(640*480))\n",
    "depthFrames = depthFrames.reshape((numOfFrames, 480, 640))\n",
    "numOfFrames = numOfFrames/2\n",
    "\n",
    "envDepthFrames = depthFrames[::2]\n",
    "envFrameCount = 30 if numOfFrames>30 else numOfFrames\n",
    "smoothedEnv = np.zeros(envDepthFrames[0].shape)\n",
    "q1 = int(envFrameCount/4)\n",
    "\n",
    "for frameNum in range(q1,q1+10):\n",
    "    img=envDepthFrames[frameNum].astype(np.float32)\n",
    "    img,maxDepth=normalizeImage(img)\n",
    "    #cv2.imshow('env',img)\n",
    "    floorRemoved,__=normalizeImage(removeFloor(img*255,9))\n",
    "    #cv2.imshow('floorRemoved',floorRemoved)\n",
    "    floorRemoved = floorRemoved*maxDepth\n",
    "    distantFiltered = removeFar(floorRemoved,4000)\n",
    "    #cv2.imshow('distantFiltered',normalizeImage(distantFiltered)[0])\n",
    "    smoothedEnv = smoothedEnv + (distantFiltered/(10))\n",
    "    #cv2.waitKey()\n",
    "    \n",
    "cv2.imshow('smoothedEnv',normalizeImage(smoothedEnv)[0])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthFilePath = <depthFilePath>\n",
    "depthFrames = np.fromfile(depthFilePath, dtype = \"uint16\")\n",
    "numOfFrames = int(depthFrames.shape[0]/(640*480))\n",
    "depthFrames = depthFrames.reshape((numOfFrames, 480, 640))\n",
    "numOfFrames = numOfFrames/2\n",
    "\n",
    "env = smoothedEnv\n",
    "silhoutte=[]\n",
    "actionFrameCount = int(numOfFrames)\n",
    "previousSilhouttePosition=None\n",
    "lastFrame = None\n",
    "\n",
    "for frameNum in range(actionFrameCount):\n",
    "    silhouetteAvailable = True\n",
    "\n",
    "    original = depthFrames[::2][frameNum].astype(np.float64)\n",
    "\n",
    "    normalizedOriginal,maxDepth = normalizeImage(original)\n",
    "    cv2.imshow('original',normalizedOriginal)\n",
    "    \n",
    "    #remove floor\n",
    "    floorRemoved=removeFloor(normalizedOriginal*255,9)        \n",
    "    floorRemoved,__=normalizeImage(floorRemoved)\n",
    "    floorRemoved=floorRemoved*maxDepth\n",
    "    \n",
    "    #remove background beyond threshold\n",
    "    distantFiltered = removeFar(floorRemoved,4000)\n",
    "    foreground = distantFiltered-env\n",
    "    img = foreground.astype(np.float32)  \n",
    "    ret,binaryImg = cv2.threshold(normalizeImage(img)[0],0.6,1,cv2.THRESH_BINARY)\n",
    "    realDepthSilhouette = (binaryImg*normalizedOriginal)\n",
    "    #ccl\n",
    "    labels = get_components(realDepthSilhouette,0.02)\n",
    "    Lbls, lbl_count = np.unique(np.array([i for i in labels.values()]),return_counts=True)\n",
    "    \n",
    "    croppedLabels = []\n",
    "    croppedLblsWithCentroids={} \n",
    "\n",
    "    for i in range(len(Lbls)):\n",
    "        if(lbl_count[i]>375 and lbl_count[i]<55000):\n",
    "            croppedLabels.append(Lbls[i])\n",
    "            centroids,width,height=getStatsOfLabel(realDepthSilhouette,Lbls[i],labels)\n",
    "            if(lbl_count[i] not in croppedLblsWithCentroids):\n",
    "                newLblCount=lbl_count[i]+i*0.001   ###to avoid replace of duplicate label counts\n",
    "                croppedLblsWithCentroids[newLblCount]=centroids,(width,height),Lbls[i]\n",
    "\n",
    "    if(len(croppedLblsWithCentroids)>1):\n",
    "\n",
    "        while True: \n",
    "            if(len(croppedLblsWithCentroids)>0):\n",
    "                centroidOfMax = croppedLblsWithCentroids[max(croppedLblsWithCentroids)][0]\n",
    "                if(previousSilhouttePosition == None):\n",
    "                    break\n",
    "                elif(abs(centroidOfMax[0]-previousSilhouttePosition[0])>200 or abs(centroidOfMax[1]-previousSilhouttePosition[1])>200):\n",
    "                    croppedLabels.remove(croppedLblsWithCentroids[max(croppedLblsWithCentroids)][2])\n",
    "                    croppedLblsWithCentroids.pop(max(croppedLblsWithCentroids))\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                silhouetteAvailable = False\n",
    "                break\n",
    "    \n",
    "\n",
    "    if (silhouetteAvailable and len(croppedLblsWithCentroids)>0):\n",
    "        centroidOfMax = croppedLblsWithCentroids[max(croppedLblsWithCentroids)][0]\n",
    "        sizeOfMax = croppedLblsWithCentroids[max(croppedLblsWithCentroids)][1]\n",
    "        for croppedLabel in croppedLblsWithCentroids:\n",
    "            labelX = croppedLblsWithCentroids[croppedLabel][0][0]\n",
    "            labelY = croppedLblsWithCentroids[croppedLabel][0][1]\n",
    "            labelName = croppedLblsWithCentroids[croppedLabel][2]\n",
    "\n",
    "            if(abs(labelX-centroidOfMax[0])>1.2*sizeOfMax[0] or abs(labelY-centroidOfMax[1])>1.5*sizeOfMax[1]):\n",
    "                croppedLabels.remove(labelName)\n",
    "    \n",
    "    if (len(croppedLblsWithCentroids)==0):\n",
    "        silhouetteAvailable = False\n",
    "\n",
    "    if (silhouetteAvailable):\n",
    "        img = np.zeros(original.shape)\n",
    "\n",
    "        for y, x in product(range(img.shape[0]), range(img.shape[1])):\n",
    "            if (y,x) in labels and labels[(y,x)] in croppedLabels:\n",
    "                img[y,x]=1\n",
    "            else:\n",
    "                img[y,x]=0\n",
    "\n",
    "        cclImg =(original*img).astype(np.uint16)\n",
    "\n",
    "        previousSilhouttePosition = getCentroid(cclImg)\n",
    "        silhoutte.append(np.array(cclImg))\n",
    "        lastFrame = frameNum\n",
    "    else:\n",
    "        if(len(silhoutte)>0):\n",
    "            silhoutte.append(silhoutte[-1])\n",
    "    cv2.imshow('Silhouette',normalizedOriginal*img)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "cv2.destroyAllWindows()    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
